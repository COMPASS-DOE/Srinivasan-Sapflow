---
title: "TEMPEST Sapflow Initial Analysis"
author: "Radha Srinivasan"
date: 'r Sys.Date()'
output: 
  html_document:
    toc: true 
    toc_float: true 
    code_folding: hide
---

This code tests for statistically significant differences in tulip poplar sapflow due to TEMPEST saltwater treatment. We use a generalized linear mixed model (GLMM) on BACI structured data, treating years as a random effect. 
This method is adapted from Pardini et. al. (2018).

Load packages:
```{r message = FALSE}
#General packages: 
library(tidyr)
library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
```

```{r message = FALSE}
#Analysis-specific packages:

# List of packages to be used in the R session
.packages = c("lme4", "AICcmodavg", "MuMIn", "pbkrtest",
              "parallel", "data.table", "blmeco", "lsmeans")
# Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
# Attach packages
sapply(.packages, require, character.only=TRUE)
```

Read in TEMPEST sapflow data:
```{r}
full_data <- readRDS("Full_21_24.rds")
```

Define the TEMPEST flood events, as well as the 2 weeks before and after flooding: 
```{r}
#TEMPEST EVENTS
tempest_events <- bind_rows(
  tibble( Year = 2021, flood_start = "2021-06-12", flood_end = "2021-06-12"), #average date = June 12
  tibble( Year = 2022, flood_start = "2022-06-22", flood_end = "2022-06-22"), #June 22
  tibble( Year = 2023, flood_start = "2023-06-06", flood_end = "2023-06-07"), #June 6, 7
  tibble( Year = 2024, flood_start = "2024-06-11", flood_end = "2024-06-13")) #June 11, 12, 13

tempest_events %>%
  mutate(flood_start = ymd(flood_start),
         flood_end = ymd(flood_end)) -> events

#window of data to look at
window <- days(15)

```

Isolate the data to focus on tulip poplar, saltwater and control treatments, weeks before and after treatment, and midday sapflow (between 11 am and 2 pm).
```{r message = FALSE}
#Tidy up our data: 
full_data %>%
  dplyr::select(Year, Species, ID, TIMESTAMP, Plot, `F`) %>%
  mutate(Date = as_date(date(TIMESTAMP)),
         Hour = hour(TIMESTAMP)) %>%
  left_join(events) %>%
  group_by(Year) %>%
  mutate(data_start = flood_start - window,
         data_end = flood_end + window) %>%
  filter(Date > data_start & Date < flood_start |
         Date < data_end & Date > flood_end,
         Hour < 14, Hour >= 11, 
         Plot != "Freshwater",
         Species == "Tulip Poplar") %>%
  ungroup() -> tulip_salt
```

Further tidy dataframe for BACI analysis; filter for outliers and confirm by plotting entire four-year sapflow. 
```{r message = FALSE, warning = FALSE}
tulip_salt %>%
  group_by(Year) %>%
  mutate(BA = ifelse(Date > flood_end, "After", "Before"),
         Year = as.factor(Year),
         ID = as.factor(ID),
         BA = as.factor(BA),
         Plot = as.factor(Plot)) %>%
  filter(`F` < 6e-06) %>% #remove outliers, ggplot below for confirmation
  group_by(Date, Plot, ID, Year, BA, flood_start, flood_end) %>%
  summarise(F_avg = mean(`F`, na.rm = TRUE),
            n = n()) %>%
  ungroup()-> tsb_1


ggplot(tulip_salt[tulip_salt$`F` < 6e-06,],
       aes(Date, `F`, color = ID)) +
  geom_point() + facet_grid(Plot~Year, scales = "free")

ggplot(tsb_1,
       aes(Date, F_avg, color = ID, shape = BA)) +
  geom_point() + facet_grid(Plot~Year, scales = "free")
```

Visualize all data as part of BACI model, with timescale represented as days before/after flood events:       
```{r}
tsb_1 %>%
  group_by(Year) %>%
  mutate(Day = ifelse(BA == "Before",
                      - as.numeric(flood_start - Date),
                      as.numeric(Date - flood_end))) -> tsb_2

ggplot(tsb_2, aes(Day, F_avg, color = ID, shape = BA)) +
  geom_point(size = 2.5) + facet_grid(Plot~Year, scales = "free")

```

We want to use the following general linear mixed model: 

F_avg ~ BA + Plot  + BA*Plot +
        (1|ID) + (1|Year) + (1|ID:Year)
        
In which 'Plot' is the control/impact treatment effect, 'BA' is the pre/post flood treatment effect, and tree ID and Year are random effects. 

*Note that although, flooding intensity increases each year, we ignore this effect for now. 

First, test for the statistical significance of the final term (1|ID:Year), the interaction of the ID and Year random effects, using an AIC comparison. 

```{r warning = FALSE}
Cand.set <- list()

Cand.set[[1]] <- glmer(F_avg ~ BA + Plot  + BA*Plot +
                         (1|ID) + (1|Year),
                       data = tsb_2, family = gaussian)
model.noint <- Cand.set[[1]]

Cand.set[[2]] <- glmer(F_avg ~ BA + Plot + BA*Plot +
                         (1|ID) + (1|Year) +
                         (1|ID:Year),
                       data = tsb_2, family = gaussian)
model.int <- Cand.set[[2]]

AIC.res.table <- aictab(cand.set = list(Cand.set[[1]], Cand.set[[2]]), 
                        modnames = paste0("Cand.set_", c(1,2)), 
                        second.ord = TRUE)
AIC.res.table
```
Choose the model with the lowest AICc value (i.e. largest negative value); this suggests that the second model, which includes the random effects interaction term, is a better fit for our data.

Next, check for normally distributed data:
```{r}
qqnorm(residuals(model.int), 
       main = "Q-Q plot - residuals")
qqline(residuals(model.int), col="red")

# inspecting the random effects (see also Bolker, 2009 - supp 1)
qqnorm(unlist(ranef(model.int)), 
       main = "Q-Q plot, random effects")
qqline(unlist(ranef(model.int)), col="red")

# fitted vs residuals
scatter.smooth(fitted(model.int), 
               residuals(model.int, type="pearson"),
               main="fitted vs residuals",
               xlab="Fitted Values", ylab="Residuals")
abline(h=0, col="red")
```
Data appears to be slightly right-skewed. Let's test a few different transformations on our data and compare the resulting skewness using the e1071 package. 
Values of skewness closer to 0 indicate more normally distributed data.
```{r}
library(e1071)
current_skewness <- skewness(tsb_2$F_avg)
print(paste("Current Skewness:", current_skewness))

# Logarithmic Transformation
log_transformed_response <- log(tsb_2$F_avg + 1)

# Square Root Transformation
sqrt_transformed_response <- sqrt(tsb_2$F_avg)

# Inverse Transformation
inv_transformed_response <- 1 / tsb_2$F_avg

log_skewness <- skewness(log_transformed_response)
sqrt_skewness <- skewness(sqrt_transformed_response)
inv_skewness <- skewness(inv_transformed_response)

print(paste("Log Transformation Skewness:", log_skewness))
print(paste("Square Root Transformation Skewness:", sqrt_skewness))
print(paste("Inverse Transformation Skewness:", inv_skewness))

```
A square root transformation on our data seems to be best. Transform our original glmm and check again for normality with a histogram and by plotting residuals: 

```{r}
model.int_sr <- glmer(sqrt(F_avg) ~ BA + Plot + BA*Plot +
           (1|ID) + (1|Year) +
           (1|ID:Year),
         data = tsb_2, family = gaussian)

ggplot(tsb_2, aes(sqrt(F_avg))) + geom_histogram() +
  facet_grid(Plot~.)

qqnorm(residuals(model.int_sr), 
       main = "Q-Q plot - residuals")
qqline(residuals(model.int_sr), col="red")
```

Check again for normality of random effects using this transformed model: 

```{r}
# inspecting the random effects (see also Bolker, 2009 - supp 1)
qqnorm(unlist(ranef(model.int_sr)), 
       main = "Q-Q plot, random effects")
qqline(unlist(ranef(model.int_sr)), col="red")

# fitted vs residuals
scatter.smooth(fitted(model.int_sr), 
               residuals(model.int_sr, type="pearson"),
               main="fitted vs residuals",
               xlab="Fitted Values", ylab="Residuals")
abline(h=0, col="red")
```
Looks good!

Lastly, test for the significance of the BACI interaction term using a parametric bootstrap comparison between nested models: 

```{r warning = FALSE}
model.noint_sr <- glmer(sqrt(F_avg) ~ BA + Plot +
                         (1|ID) + (1|Year) + (1|ID:Year),
                       data = tsb_2, family = gaussian)

refdist.pb.100.interaction <- PBrefdist(largeModel = model.int_sr, 
                                        smallModel = model.noint_sr, 
                                        nsim = 100, seed = 1989)

compar.interaction.100 <- PBmodcomp(largeModel = model.int_sr, 
                                    smallModel = model.noint_sr,
                                    ref = refdist.pb.100.interaction)
compar.interaction.100
```
Both the limited ratio test and the parametric bootstrap test yield statistically significant p-values. This indicates that the BACI interaction term does have a statistically significant effect in the glmm. 



